{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save np array to hdf5\n",
    "df = pd.DataFrame([[1, 1.0, 'a']], columns=['x', 'y', 'z'])\n",
    "df.to_hdf('./store.h5', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reread = pd.read_hdf('./store.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x    y  z\n",
       "0  1  1.0  a"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['a','apple', 'appache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = marisa_trie.Trie(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'appache']\n"
     ]
    }
   ],
   "source": [
    "print(trie.prefixes('appache'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'appache', 'apple']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0), ('appache', 1), ('apple', 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_build',\n",
       " '_config_flags',\n",
       " 'frombytes',\n",
       " 'get',\n",
       " 'has_keys_with_prefix',\n",
       " 'items',\n",
       " 'iter_prefixes',\n",
       " 'iteritems',\n",
       " 'iterkeys',\n",
       " 'key_id',\n",
       " 'keys',\n",
       " 'load',\n",
       " 'mmap',\n",
       " 'prefixes',\n",
       " 'read',\n",
       " 'restore_key',\n",
       " 'save',\n",
       " 'tobytes',\n",
       " 'write']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(trie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48280,
     "status": "ok",
     "timestamp": 1568166190977,
     "user": {
      "displayName": "Dmitry Vengertsev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDYD27Z8EhBcFDMesTklMQKc27chgzd92EokKwqJw=s64",
      "userId": "11039444983797551480"
     },
     "user_tz": 360
    },
    "id": "ihKjA9UrM_kO",
    "outputId": "dc00057b-c043-4a3f-92f7-a5d8277697e0"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create ground truth with all states pre-calculated\n",
    "'''\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import marisa_trie\n",
    "# https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python\n",
    "import glob\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "import h5py\n",
    "\n",
    "# ground truth parameters\n",
    "char_seq_len=10\n",
    "delta_step=1\n",
    "# Configs\n",
    "data_folder = \"data/\"\n",
    "train_dataset = data_folder + \"training_dataset/nietzsche.txt\"\n",
    "folder_models = data_folder + \"trained_models/\"\n",
    "output_ground_truth = data_folder + \"ground_truth/\"\n",
    "\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, tokens, n_hidden=612, n_layers=4,\n",
    "                               drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        # creating character dictionaries\n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        ## TODO: define the LSTM\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## TODO: define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## TODO: define the final, fully-connected output layer\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "                \n",
    "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        ## TODO: pass through a dropout layer\n",
    "        out = self.dropout(r_output)\n",
    "        \n",
    "        # Stack up LSTM outputs using view\n",
    "        # you may need to use contiguous to reshape the output\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        \n",
    "        ## TODO: put x through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden\n",
    "      \n",
    "      \n",
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot\n",
    "  \n",
    "\n",
    "def predict(net, char, h=None, top_k=None, return_vectors=True):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        \n",
    "        # tensor inputs\n",
    "        x = np.array([[net.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(net.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        # print(\"h={}\".format(h))\n",
    "        # print(\"len h {}\".format(len(h)))\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        \n",
    "        # print(\"Is CUDA: {}\".format(inputs.is_cuda))\n",
    "        # inputs.is_cuda\n",
    "\n",
    "        \n",
    "        out, h = net(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        # apply softmax to get p probabilities for the likely next character giving x\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        \n",
    "        \n",
    "        # keep probability to use later\n",
    "        prob = p.numpy().squeeze()\n",
    "        \n",
    "        if not return_vectors:        \n",
    "          char_index = np.argmax(prob)\n",
    "          char_pred = net.int2char[char_index]\n",
    "          prob_pred = prob[char_index]\n",
    "          return char_pred, h, prob_pred \n",
    "        else: \n",
    "          return h, prob \n",
    "#         # get top characters\n",
    "#         # considering the k most probable characters with topk method\n",
    "#         if top_k is None:\n",
    "#             top_ch = np.arange(len(net.chars))\n",
    "#         else:\n",
    "#             p, top_ch = p.topk(top_k)\n",
    "#             top_ch = top_ch.numpy().squeeze()        \n",
    "        \n",
    "#         # select the likely next character with some element of randomness\n",
    "#         p = p.numpy().squeeze()\n",
    "#         char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "#         # return the encoded value of the predicted char and the hidden state\n",
    "#        return net.int2char[char], h, prob\n",
    "\n",
    "\n",
    "     \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48256,
     "status": "ok",
     "timestamp": 1568166190979,
     "user": {
      "displayName": "Dmitry Vengertsev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDYD27Z8EhBcFDMesTklMQKc27chgzd92EokKwqJw=s64",
      "userId": "11039444983797551480"
     },
     "user_tz": 360
    },
    "id": "3ZzWDzobYiKb",
    "outputId": "98f8cfd9-c0ff-4343-a86b-fbd24b7e8eff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54441,
     "status": "ok",
     "timestamp": 1568166197182,
     "user": {
      "displayName": "Dmitry Vengertsev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDYD27Z8EhBcFDMesTklMQKc27chgzd92EokKwqJw=s64",
      "userId": "11039444983797551480"
     },
     "user_tz": 360
    },
    "id": "QbDT7nln4_BI",
    "outputId": "787879ab-2cb8-4ae9-c456-f8c991852fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Training data processing - Started. ***************\n",
      "content_size = 580741 tokens_max_cnt = 580741\n",
      "Example of tokens ['use the la', 'od grounds', ' sinful in']\n",
      "tokens_incr = 1418404\n",
      "Example of tokens incr [' one sta', 'inal enoug', 'oohuman f', ' asses', 'esses his ', 'and goes', 'the tedi', 'him  114 t', 'ianism by ', 'efic', 'as life', ' victim', 'f denial', 'nes acts ', 'bted first', 'ng disposi', 'lish eq', 'ly losing', 'to so emph', 'emocrats', 'eoise ju', 'he spee', ' its def', 'ison and a', 'ctions pr', 'er v the n', 'ape obedie', 'w of hu', 'angled to', 'ropical l']\n",
      "Min token len: 1\n",
      "Max token len: 10\n",
      "Avg token len: 8.26963051429635\n",
      "********** Training data processing - Completed. ***************\n",
      "********** Construct Ground Truth Data Structure=Prefix tree - Started. ***************\n",
      "['s', 'se', 'see', 'see ', 'see m', 'see mo']\n",
      "********** Construct Ground Truth Data Structure=Prefix tree - Completed. ***************\n",
      "model_fname_list: ['data/trained_models\\\\model_1024_1_160_50', 'data/trained_models\\\\model_1024_1_80_50', 'data/trained_models\\\\model_1024_4_80_50', 'data/trained_models\\\\model_124_1_160_50', 'data/trained_models\\\\model_124_1_80_50', 'data/trained_models\\\\model_124_4_160_50', 'data/trained_models\\\\model_124_4_80_50', 'data/trained_models\\\\model_512_1_160_50', 'data/trained_models\\\\model_512_1_80_50', 'data/trained_models\\\\model_512_4_160_50', 'data/trained_models\\\\model_512_4_80_50']\n"
     ]
    }
   ],
   "source": [
    "print(\"********** Training data processing - Started. ***************\")\n",
    "f = open(train_dataset, 'r')\n",
    "content = f.read()\n",
    "import re\n",
    "s = \"string. With. Punctuation?\"\n",
    "s = re.sub(r'[^\\w\\s]','',content)\n",
    "s = re.sub('\\n', ' ', s)\n",
    "s = str.lower(s)\n",
    "content = s\n",
    "\n",
    "content_size = len(content)\n",
    "tokens_max_cnt = int(content_size/delta_step)\n",
    "print('content_size = {} tokens_max_cnt = {}'.format(content_size, tokens_max_cnt))\n",
    "\n",
    "tokens_all = set()\n",
    "for i in range(0, tokens_max_cnt):  \n",
    "  start = int(i*delta_step)\n",
    "  end = int(i*delta_step + char_seq_len)\n",
    "  # print('start = {}, end = {}'.format(start, end))  \n",
    "  seq = content[start:end]\n",
    "  # print('seq = {}'.format(seq))\n",
    "  tokens_all.add(seq)\n",
    "  \n",
    "tokens = list(tokens_all)\n",
    "print('Example of tokens {}'.format(tokens[0:3]))\n",
    "\n",
    "tokens_incr = set() # incremental tokens\n",
    "\n",
    "for token in tokens:\n",
    "  for i in range(0, len(token)+1):\n",
    "    token_i = token[0: i]\n",
    "    #print(token_i)\n",
    "    tokens_incr.add(token_i)\n",
    "tokens_incr = list(tokens_incr)\n",
    "tokens_incr.remove('')\n",
    "print(\"tokens_incr = {}\".format(len(tokens_incr)))\n",
    "print('Example of tokens incr {}'.format(tokens_incr[0:30]))\n",
    "tokens_len = [ len(x) for x in tokens_incr]\n",
    "print(\"Min token len: {}\".format(np.min(tokens_len)))\n",
    "print(\"Max token len: {}\".format(np.max(tokens_len)))\n",
    "print(\"Avg token len: {}\".format(np.mean(tokens_len)))\n",
    "print(\"********** Training data processing - Completed. ***************\")\n",
    "\n",
    "\n",
    "print(\"********** Construct Ground Truth Data Structure=Prefix tree - Started. ***************\")\n",
    "trie = marisa_trie.Trie(tokens_incr)\n",
    "print(trie.prefixes('see mo'))\n",
    "# object_methods = [method_name for method_name in dir(trie)\n",
    "#                   if callable(getattr(trie, method_name))]\n",
    "# object_methods\n",
    "print(\"********** Construct Ground Truth Data Structure=Prefix tree - Completed. ***************\")\n",
    "\n",
    "# 1. get list of models from a directory\n",
    "\n",
    "model_fname_list = glob.glob(folder_models+\"/*\")\n",
    "print(\"model_fname_list: {}\".format(model_fname_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vhlLTfC_Jt2"
   },
   "outputs": [],
   "source": [
    "# for model_fname in model_fname_list:\n",
    "#   print(\"********** model_fname = {} *********\".format(model_fname))\n",
    "#   with open(model_fname, 'rb') as f:\n",
    "#       checkpoint = torch.load(f)\n",
    "#   print(loaded.cuda())\n",
    "#   loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "#   loaded.load_state_dict(checkpoint['state_dict'])\n",
    "#   print(\"Model info: {}\".format(loaded))\n",
    "  \n",
    "#   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60049,
     "status": "ok",
     "timestamp": 1568166202820,
     "user": {
      "displayName": "Dmitry Vengertsev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDYD27Z8EhBcFDMesTklMQKc27chgzd92EokKwqJw=s64",
      "userId": "11039444983797551480"
     },
     "user_tz": 360
    },
    "id": "1nK5-S9gZ9eP",
    "outputId": "e8d86dcb-8787-41b2-df9c-9fe90b1117c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** model_fname = data/trained_models/model_124_1_80_50 *********\n",
      "Model info: CharRNN(\n",
      "  (lstm): LSTM(44, 124, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=124, out_features=44, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_fname = 'data/trained_models/model_124_1_80_50'\n",
    "model_base_name = os.path.basename(model_fname)\n",
    "\n",
    "\n",
    "print(\"********** model_fname = {} *********\".format(model_fname))\n",
    "with open(model_fname, 'rb') as f:\n",
    "      checkpoint = torch.load(f)\n",
    "model = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model info: {}\".format(model))\n",
    "\n",
    "  # Add for-loop for elements of tokens_incr\n",
    "  \n",
    "  # 2. predict Y and H for all elements of marisa-trie\n",
    "  # 3. save as trie? or dict?!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aTnGYUEfjrx"
   },
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "class GroundTruth :\n",
    "  \n",
    "  def __init__(self, _trie, _ymap, _hmap):\n",
    "    self.trie = _trie\n",
    "    self.ymap = _ymap # mapping of trie node ID to y variable\n",
    "    self.hmap = _hmap # mapping of trie node ID to hidden state variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59994,
     "status": "ok",
     "timestamp": 1568166202822,
     "user": {
      "displayName": "Dmitry Vengertsev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDYD27Z8EhBcFDMesTklMQKc27chgzd92EokKwqJw=s64",
      "userId": "11039444983797551480"
     },
     "user_tz": 360
    },
    "id": "zWVuvNjuufqY",
    "outputId": "0a1fc95b-e7a7-4421-b6c9-530396cf9add"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60058,
     "status": "ok",
     "timestamp": 1568166202908,
     "user": {
      "displayName": "Dmitry Vengertsev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDYD27Z8EhBcFDMesTklMQKc27chgzd92EokKwqJw=s64",
      "userId": "11039444983797551480"
     },
     "user_tz": 360
    },
    "id": "DOtP1Z34JEYM",
    "outputId": "be26adeb-7dc5-4e37-ecbb-3bf71490bfe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i33MILmQyv9J"
   },
   "outputs": [],
   "source": [
    "ymap = {}\n",
    "hmap = {}\n",
    "train_on_gpu = True\n",
    "\n",
    "def predict_seq(_chars, _model):\n",
    "  h = model.init_hidden(1)\n",
    "  for ch in _chars:\n",
    "    h, prob = predict(model, ch, h)\n",
    "    # print(\"ch = {}, char = {}, prob = {}\".format(ch, char, prob))    \n",
    "  return h, prob      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie.save(output_ground_truth+'/gt_'+model_base_name+'.marisa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = h5py.File(output_ground_truth+'/gt_'+model_base_name+'_'+str(part)+'_states.h5py', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_keys = trie.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = len(trie_keys)/4.0\n",
    "start = round((part-1)*delta)\n",
    "end = round(part*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part:1, start=0, end=354601\n"
     ]
    }
   ],
   "source": [
    "print(\"part:{}, start={}, end={}\".format(part, start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354601"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_ids = [x[1] for x in trie.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 40, 788, 6745, 30956, 93672, 215776, 409317, 678428, 1018535]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_ids[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354601"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trie.items()[start : end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 0),\n",
       " (' a', 40),\n",
       " (' an', 788),\n",
       " (' and', 6745),\n",
       " (' and ', 30956),\n",
       " (' and s', 93672),\n",
       " (' and se', 215776),\n",
       " (' and sel', 409317),\n",
       " (' and self', 678428),\n",
       " (' and self ', 1018535)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie.items()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elem =  if one i. k = 50000\n",
      "elem =  mankinda. k = 100000\n",
      "elem =  remain g. k = 150000\n",
      "elem = e left af. k = 200000\n",
      "elem = eserts. k = 250000\n",
      "elem = ey are alr. k = 300000\n",
      "elem = alsest op. k = 350000\n"
     ]
    }
   ],
   "source": [
    "# using hdf5\n",
    "k = 0\n",
    "for elem, elem_id in trie.items()[start : end]:\n",
    "  h, prob = predict_seq(elem, model)\n",
    "  f['y_'+str(elem_id)] = prob\n",
    "  f['h_'+str(elem_id)] = h[0].data.cpu().numpy() # only the values, do not save gradient\n",
    "\n",
    "  k=k+1\n",
    "  if (k%50000==0):\n",
    "    print(\"elem = {}. k = {}\".format(elem, k))\n",
    "  # if k>10:\n",
    "    # break\n",
    "  \n",
    "# model_gt = GroundTruth(trie, ymap, hmap)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read  and check that oredr of elems is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = h5py.File(output_ground_truth+'/gt_'+model_base_name+'_'+str(part)+'_states.h5py', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' a',\n",
       " ' an',\n",
       " ' and',\n",
       " ' and ',\n",
       " ' and s',\n",
       " ' and se',\n",
       " ' and sel',\n",
       " ' and self',\n",
       " ' and self ']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_keys[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_trie_keys = list(g.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.15970162e-02, 1.02252125e-04, 3.18567851e-04, 1.17493124e-04,\n",
       "       4.23897393e-02, 3.73146759e-04, 2.39318255e-02, 8.48555639e-02,\n",
       "       9.20189632e-05, 9.47463363e-02, 2.53079622e-03, 4.12827125e-03,\n",
       "       3.13363667e-03, 1.02065147e-04, 2.29419004e-02, 9.67583582e-02,\n",
       "       7.77364075e-02, 7.15183513e-03, 5.76696023e-02, 1.02002057e-04,\n",
       "       4.92777872e-05, 4.79606800e-02, 1.94603726e-02, 9.63516650e-05,\n",
       "       1.07069046e-03, 2.20848620e-03, 1.93535147e-04, 6.43221214e-02,\n",
       "       7.88175687e-02, 8.63932510e-05, 1.41437287e-02, 7.15470524e-05,\n",
       "       9.15253913e-05, 4.38000150e-02, 3.91744189e-02, 3.57919931e-02,\n",
       "       7.22919474e-04, 3.01809353e-03, 5.95195706e-05, 5.39685041e-02,\n",
       "       1.87969841e-02, 1.45215364e-02, 7.59283954e-04, 3.56424353e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['y_1018535'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__cuda_array_interface__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__idiv__',\n",
       " '__ilshift__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rfloordiv__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_backward_hooks',\n",
       " '_base',\n",
       " '_cdata',\n",
       " '_coalesced_',\n",
       " '_dimI',\n",
       " '_dimV',\n",
       " '_grad',\n",
       " '_grad_fn',\n",
       " '_indices',\n",
       " '_is_view',\n",
       " '_make_subclass',\n",
       " '_nnz',\n",
       " '_values',\n",
       " '_version',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'add',\n",
       " 'add_',\n",
       " 'addbmm',\n",
       " 'addbmm_',\n",
       " 'addcdiv',\n",
       " 'addcdiv_',\n",
       " 'addcmul',\n",
       " 'addcmul_',\n",
       " 'addmm',\n",
       " 'addmm_',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'addr_',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'any',\n",
       " 'apply_',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan2_',\n",
       " 'atan_',\n",
       " 'backward',\n",
       " 'baddbmm',\n",
       " 'baddbmm_',\n",
       " 'bernoulli',\n",
       " 'bernoulli_',\n",
       " 'bfloat16',\n",
       " 'bincount',\n",
       " 'bitwise_not',\n",
       " 'bitwise_not_',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'byte',\n",
       " 'cauchy_',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'char',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'contiguous',\n",
       " 'copy_',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'cuda',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'data_ptr',\n",
       " 'dense_dim',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'digamma',\n",
       " 'digamma_',\n",
       " 'dim',\n",
       " 'dist',\n",
       " 'div',\n",
       " 'div_',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'eig',\n",
       " 'element_size',\n",
       " 'eq',\n",
       " 'eq_',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'erfinv_',\n",
       " 'exp',\n",
       " 'exp_',\n",
       " 'expand',\n",
       " 'expand_as',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'exponential_',\n",
       " 'fft',\n",
       " 'fill_',\n",
       " 'fill_diagonal_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'float',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'fmod',\n",
       " 'fmod_',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'gather',\n",
       " 'ge',\n",
       " 'ge_',\n",
       " 'gels',\n",
       " 'geometric_',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_device',\n",
       " 'grad',\n",
       " 'grad_fn',\n",
       " 'gt',\n",
       " 'gt_',\n",
       " 'half',\n",
       " 'hardshrink',\n",
       " 'histc',\n",
       " 'ifft',\n",
       " 'index_add',\n",
       " 'index_add_',\n",
       " 'index_copy',\n",
       " 'index_copy_',\n",
       " 'index_fill',\n",
       " 'index_fill_',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'int',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'irfft',\n",
       " 'is_coalesced',\n",
       " 'is_complex',\n",
       " 'is_contiguous',\n",
       " 'is_cuda',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_leaf',\n",
       " 'is_mkldnn',\n",
       " 'is_nonzero',\n",
       " 'is_pinned',\n",
       " 'is_quantized',\n",
       " 'is_same_size',\n",
       " 'is_set_to',\n",
       " 'is_shared',\n",
       " 'is_signed',\n",
       " 'is_sparse',\n",
       " 'isclose',\n",
       " 'item',\n",
       " 'kthvalue',\n",
       " 'layout',\n",
       " 'le',\n",
       " 'le_',\n",
       " 'lerp',\n",
       " 'lerp_',\n",
       " 'lgamma',\n",
       " 'lgamma_',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_normal_',\n",
       " 'log_softmax',\n",
       " 'logdet',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lstsq',\n",
       " 'lt',\n",
       " 'lt_',\n",
       " 'lu',\n",
       " 'lu_solve',\n",
       " 'map2_',\n",
       " 'map_',\n",
       " 'masked_fill',\n",
       " 'masked_fill_',\n",
       " 'masked_scatter',\n",
       " 'masked_scatter_',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'matrix_power',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'mul_',\n",
       " 'multinomial',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'mvlgamma_',\n",
       " 'name',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'ndim',\n",
       " 'ndimension',\n",
       " 'ne',\n",
       " 'ne_',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'nelement',\n",
       " 'new',\n",
       " 'new_empty',\n",
       " 'new_full',\n",
       " 'new_ones',\n",
       " 'new_tensor',\n",
       " 'new_zeros',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'normal_',\n",
       " 'numel',\n",
       " 'numpy',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'output_nr',\n",
       " 'permute',\n",
       " 'pin_memory',\n",
       " 'pinverse',\n",
       " 'polygamma',\n",
       " 'polygamma_',\n",
       " 'pow',\n",
       " 'pow_',\n",
       " 'prelu',\n",
       " 'prod',\n",
       " 'put_',\n",
       " 'q_scale',\n",
       " 'q_zero_point',\n",
       " 'qr',\n",
       " 'qscheme',\n",
       " 'random_',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'record_stream',\n",
       " 'register_hook',\n",
       " 'reinforce',\n",
       " 'relu',\n",
       " 'relu_',\n",
       " 'remainder',\n",
       " 'remainder_',\n",
       " 'renorm',\n",
       " 'renorm_',\n",
       " 'repeat',\n",
       " 'repeat_interleave',\n",
       " 'requires_grad',\n",
       " 'requires_grad_',\n",
       " 'reshape',\n",
       " 'reshape_as',\n",
       " 'resize',\n",
       " 'resize_',\n",
       " 'resize_as',\n",
       " 'resize_as_',\n",
       " 'retain_grad',\n",
       " 'rfft',\n",
       " 'roll',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'scatter',\n",
       " 'scatter_',\n",
       " 'scatter_add',\n",
       " 'scatter_add_',\n",
       " 'select',\n",
       " 'set_',\n",
       " 'shape',\n",
       " 'share_memory_',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'sign_',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'size',\n",
       " 'slogdet',\n",
       " 'smm',\n",
       " 'softmax',\n",
       " 'solve',\n",
       " 'sort',\n",
       " 'sparse_dim',\n",
       " 'sparse_mask',\n",
       " 'sparse_resize_',\n",
       " 'sparse_resize_and_clear_',\n",
       " 'split',\n",
       " 'split_with_sizes',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'squeeze',\n",
       " 'squeeze_',\n",
       " 'sspaddmm',\n",
       " 'std',\n",
       " 'stft',\n",
       " 'storage',\n",
       " 'storage_offset',\n",
       " 'storage_type',\n",
       " 'stride',\n",
       " 'sub',\n",
       " 'sub_',\n",
       " 'sum',\n",
       " 'sum_to_size',\n",
       " 'svd',\n",
       " 'symeig',\n",
       " 't',\n",
       " 't_',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " 'to',\n",
       " 'to_dense',\n",
       " 'to_mkldnn',\n",
       " 'to_sparse',\n",
       " 'tolist',\n",
       " 'topk',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'transpose_',\n",
       " 'triangular_solve',\n",
       " 'tril',\n",
       " 'tril_',\n",
       " 'triu',\n",
       " 'triu_',\n",
       " 'trunc',\n",
       " 'trunc_',\n",
       " 'type',\n",
       " 'type_as',\n",
       " 'unbind',\n",
       " 'unfold',\n",
       " 'uniform_',\n",
       " 'unique',\n",
       " 'unique_consecutive',\n",
       " 'unsqueeze',\n",
       " 'unsqueeze_',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'view_as',\n",
       " 'where',\n",
       " 'zero_']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(h[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.4322e-03, -2.8410e-02,  3.1460e-01,  7.0690e-02, -9.0526e-02,\n",
       "           8.5714e-02,  8.1651e-02,  3.4326e-02, -1.8042e-01, -1.6631e-01,\n",
       "          -6.0355e-03, -3.2680e-01, -2.2718e-02, -9.7644e-02,  4.8761e-02,\n",
       "           1.6566e-02, -4.8820e-02, -4.6266e-02, -9.4683e-02,  1.4593e-01,\n",
       "           8.7851e-04,  2.4238e-02,  5.9539e-02,  5.5022e-03, -5.8738e-02,\n",
       "          -4.3814e-02,  2.1783e-03,  2.1565e-02,  1.0630e-02,  8.2591e-03,\n",
       "           7.4929e-03, -1.8718e-02,  2.4823e-02,  8.5742e-03, -2.8612e-02,\n",
       "          -1.0967e-01, -1.6261e-02,  4.1212e-02, -2.2671e-02, -1.4108e-01,\n",
       "          -8.6997e-02, -6.7066e-02, -2.5027e-03,  1.4641e-02,  1.0700e-01,\n",
       "           1.4883e-01, -3.8611e-02, -1.8133e-01,  8.4864e-03,  8.8618e-02,\n",
       "           7.8809e-03,  4.2759e-02,  8.3621e-02,  1.2503e-01,  1.3461e-02,\n",
       "          -2.0543e-02, -1.1269e-02,  1.3726e-01,  6.8421e-02, -9.7921e-02,\n",
       "           6.9353e-02, -2.8590e-01,  1.6102e-02, -6.4238e-02, -1.6368e-01,\n",
       "           2.4099e-04,  4.9696e-03, -1.0978e-02, -4.8460e-02,  3.4204e-01,\n",
       "          -7.3963e-03, -7.8811e-04,  3.0053e-02, -1.7919e-02, -2.5685e-01,\n",
       "           3.1968e-02,  8.9834e-03,  4.8901e-02, -3.8977e-02,  7.5414e-02,\n",
       "           4.3533e-02, -8.9039e-03, -3.5974e-02,  8.7315e-03,  5.6046e-02,\n",
       "          -4.1594e-01, -8.5867e-03,  2.0591e-02,  5.6837e-02, -1.9851e-03,\n",
       "          -1.2418e-01, -4.1532e-02,  6.9892e-02,  5.7283e-03,  2.5854e-01,\n",
       "          -1.1525e-02,  3.6749e-02, -7.5628e-02,  9.3960e-04,  2.6819e-02,\n",
       "          -1.0770e-02,  1.7857e-03,  1.5432e-02,  7.0618e-02,  5.7759e-02,\n",
       "           3.4828e-03,  3.7220e-01,  2.5265e-02, -9.0705e-02, -3.2038e-02,\n",
       "           8.8519e-02,  5.5480e-04, -1.4751e-01,  9.6564e-02,  5.2697e-03,\n",
       "          -8.7525e-03, -2.0831e-01,  4.3396e-02, -2.5460e-02,  7.0288e-03,\n",
       "           1.9336e-02, -1.1268e-02,  4.1456e-01,  4.0579e-02]]],\n",
       "       device='cuda:0', grad_fn=<CudnnRnnBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['h_0'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(elem_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pickle\n",
    "\n",
    "k = 0\n",
    "for elem in trie:\n",
    "  #print(\"elem = {}. k = {}\".format(elem, k))\n",
    "  # print(\"elem len = {}\".format(len(elem)))\n",
    "  h, prob = predict_seq(elem, model)\n",
    "  elem_id = trie[elem]\n",
    "  ymap[elem_id] = prob\n",
    "  hmap[elem_id] = h\n",
    "  k=k+1\n",
    "  if (k%50000==0):\n",
    "    print(\"elem = {}. k = {}\".format(elem, k))\n",
    "  # if k>10:\n",
    "    # break\n",
    "  \n",
    "# model_gt = GroundTruth(trie, ymap, hmap)\n",
    "\n",
    "with open(output_ground_truth+'/gt_'+model_base_name+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_gt, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vCuVvnxoeDZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elem =  if one i. k = 50000\n",
      "elem =  mankinda. k = 100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-11d300f77337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[1;31m#print(\"elem = {}. k = {}\".format(elem, k))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;31m# print(\"elem len = {}\".format(len(elem)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m   \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m   \u001b[0melem_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mymap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-4d4ece045a45>\u001b[0m in \u001b[0;36mpredict_seq\u001b[1;34m(_chars, _model)\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_chars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# print(\"ch = {}, char = {}, prob = {}\".format(ch, char, prob))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-0eca8dfd4b9d>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(net, char, h, top_k, return_vectors)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# get the character probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-0eca8dfd4b9d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m## TODO: pass through a dropout layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# Stack up LSTM outputs using view\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch37\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m    804\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[0;32m    805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for elem in trie:\n",
    "  #print(\"elem = {}. k = {}\".format(elem, k))\n",
    "  # print(\"elem len = {}\".format(len(elem)))\n",
    "  h, prob = predict_seq(elem, model)\n",
    "  elem_id = trie[elem]\n",
    "  ymap[elem_id] = prob\n",
    "  hmap[elem_id] = h\n",
    "  k=k+1\n",
    "  if (k%50000==0):\n",
    "    print(\"elem = {}. k = {}\".format(elem, k))\n",
    "  # if k>10:\n",
    "    # break\n",
    "  \n",
    "# model_gt = GroundTruth(trie, ymap, hmap)\n",
    "\n",
    "with open(output_ground_truth+'/gt_'+model_base_name+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_gt, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MkH4uo1uYUz6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rinGoifYUxD"
   },
   "outputs": [],
   "source": [
    "# Run before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kc0j_gpSYUtx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "calc_ground_truth.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
