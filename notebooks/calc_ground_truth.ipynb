{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "calc_ground_truth.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihKjA9UrM_kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Create ground truth with all states pre-calculated\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMUw0PAM5D-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_seq_len=10\n",
        "delta_step=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VNmhHmkOKrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmGNhNCKOS51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configs\n",
        "data_folder = \"/content/drive/My Drive/TensorSMC/check_char_lstm/data/\"\n",
        "train_dataset = data_folder + \"training_dataset/nietzsche.txt\"\n",
        "folder_models = data_folder + \"trained_models/\"\n",
        "output_ground_truth = data_folder + \"ground_truth/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZX59lYQPps0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, tokens, n_hidden=612, n_layers=4,\n",
        "                               drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        \n",
        "        # creating character dictionaries\n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "        \n",
        "        ## TODO: define the LSTM\n",
        "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        ## TODO: define a dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "        ## TODO: define the final, fully-connected output layer\n",
        "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "                \n",
        "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        ## TODO: pass through a dropout layer\n",
        "        out = self.dropout(r_output)\n",
        "        \n",
        "        # Stack up LSTM outputs using view\n",
        "        # you may need to use contiguous to reshape the output\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        \n",
        "        ## TODO: put x through the fully-connected layer\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        # return the final output and the hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7qt4WhHQCnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, char, h=None, top_k=None):\n",
        "        ''' Given a character, predict the next character.\n",
        "            Returns the predicted character and the hidden state.\n",
        "        '''\n",
        "        \n",
        "        # tensor inputs\n",
        "        x = np.array([[net.char2int[char]]])\n",
        "        x = one_hot_encode(x, len(net.chars))\n",
        "        inputs = torch.from_numpy(x)\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        # detach hidden state from history\n",
        "        h = tuple([each.data for each in h])\n",
        "        # get the output of the model\n",
        "        out, h = net(inputs, h)\n",
        "\n",
        "        # get the character probabilities\n",
        "        # apply softmax to get p probabilities for the likely next character giving x\n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "        \n",
        "        \n",
        "        # keep probability to use later\n",
        "        prob = p.numpy().squeeze()\n",
        "        char_index = np.argmax(prob)\n",
        "        char_pred = net.int2char[char_index]\n",
        "        prob_pred = prob[char_index]\n",
        "        \n",
        "#         # get top characters\n",
        "#         # considering the k most probable characters with topk method\n",
        "#         if top_k is None:\n",
        "#             top_ch = np.arange(len(net.chars))\n",
        "#         else:\n",
        "#             p, top_ch = p.topk(top_k)\n",
        "#             top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "        \n",
        "#         # select the likely next character with some element of randomness\n",
        "#         p = p.numpy().squeeze()\n",
        "#         char = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "#         # return the encoded value of the predicted char and the hidden state\n",
        "#        return net.int2char[char], h, prob\n",
        "        return char_pred, h, prob_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QbDT7nln4_BI",
        "colab": {}
      },
      "source": [
        "# Read file to get all the words.\n",
        "f = open(train_dataset, 'r')\n",
        "content = f.read()\n",
        "import re\n",
        "s = \"string. With. Punctuation?\"\n",
        "s = re.sub(r'[^\\w\\s]','',content)\n",
        "s = re.sub('\\n', ' ', s)\n",
        "s = str.lower(s)\n",
        "content = s\n",
        "\n",
        "content_size = len(content)\n",
        "tokens_max_cnt = int(content_size/delta_step)\n",
        "print('content_size = {} tokens_max_cnt = {}'.format(content_size, tokens_max_cnt))\n",
        "\n",
        "tokens_all = set()\n",
        "for i in range(0, tokens_max_cnt):  \n",
        "  start = int(i*delta_step)\n",
        "  end = int(i*delta_step + char_seq_len)\n",
        "  # print('start = {}, end = {}'.format(start, end))  \n",
        "  seq = content[start:end]\n",
        "  # print('seq = {}'.format(seq))\n",
        "  tokens_all.add(seq)\n",
        "  \n",
        "tokens = list(tokens_all)\n",
        "print('Example of tokens {}'.format(tokens[0:3]))\n",
        "\n",
        "tokens_incr = set() # incremental tokens\n",
        "\n",
        "for token in tokens:\n",
        "  for i in range(0, len(token)+1):\n",
        "    token_i = token[0: i]\n",
        "    tokens_incr.add(token_i)\n",
        "tokens_incr = list(tokens_incr)\n",
        "len(tokens_incr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vhlLTfC_Jt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvXnkgewfdUP",
        "colab_type": "text"
      },
      "source": [
        "Creating Ground Truth Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvqaZhqwGTqp",
        "colab_type": "code",
        "outputId": "85330dda-45f2-4b16-882d-7a6e310222b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!pip install marisa-trie\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 13.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 4.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: marisa-trie\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=862234 sha256=5d4abc68269d29d15b0e75874516bdb64a328deb55882a48e64c88bcdab50902\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built marisa-trie\n",
            "Installing collected packages: marisa-trie\n",
            "Successfully installed marisa-trie-0.7.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1Hef_6hGTov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import marisa_trie\n",
        "# https://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTy-SMZQUOyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trie = marisa_trie.Trie(tokens_incr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFR4Cm1cZSH_",
        "colab_type": "code",
        "outputId": "bc33ad94-ebbc-43c6-b1c4-014906b7a371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trie.prefixes('see mo')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 's', 'se', 'see', 'see ', 'see m', 'see mo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i__RSHSyZSDY",
        "colab_type": "code",
        "outputId": "29df91f1-9dad-4dcd-9160-eb5f6716d6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "source": [
        "object_methods = [method_name for method_name in dir(trie)\n",
        "                  if callable(getattr(trie, method_name))]\n",
        "object_methods"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '_build',\n",
              " '_config_flags',\n",
              " 'frombytes',\n",
              " 'get',\n",
              " 'has_keys_with_prefix',\n",
              " 'items',\n",
              " 'iter_prefixes',\n",
              " 'iteritems',\n",
              " 'iterkeys',\n",
              " 'key_id',\n",
              " 'keys',\n",
              " 'load',\n",
              " 'mmap',\n",
              " 'prefixes',\n",
              " 'read',\n",
              " 'restore_key',\n",
              " 'save',\n",
              " 'tobytes',\n",
              " 'write']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YD2MRRvf14P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNtqzqfbPM52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. get list of models from a directory\n",
        "\n",
        "model_list = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dnOdSBdPM83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in model_list:\n",
        "  with open(model, 'rb') as f:\n",
        "      checkpoint = torch.load(f)\n",
        "\n",
        "  loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
        "  loaded.load_state_dict(checkpoint['state_dict'])  \n",
        "  \n",
        "  # 2. predict Y and H for all elements of marisa-trie\n",
        "  # 3. save \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}